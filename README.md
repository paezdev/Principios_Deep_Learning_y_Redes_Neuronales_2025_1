# Principios de Deep Learning y Redes Neuronales ‚Äî Actividades 1, 2, 3 y 4

## Descripci√≥n

Este repositorio corresponde al desarrollo progresivo de un proyecto de reconocimiento utilizando redes neuronales. Se documentan los experimentos y resultados de cuatro entregas principales:

- **Actividad 1:** Detecci√≥n de fraudes financieros con un modelo b√°sico de red neuronal.
- **Actividad 2:** An√°lisis de dos casos pr√°cticos aplicando redes **CNN** para im√°genes y **RNN** para texto.
- **Actividad 3:** Implementaci√≥n b√°sica de una RNN para an√°lisis de sentimiento de texto.
- **Actividad 4:** Mejora de un modelo LSTM bidireccional con embeddings FastText, optimizaci√≥n de hiperpar√°metros con Keras Tuner, regularizaci√≥n y exportaci√≥n para producci√≥n.

---

## üìÅ Estructura del Proyecto

```
.
‚îú‚îÄ‚îÄ docs
‚îÇ   ‚îú‚îÄ‚îÄ actividad 1
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ paez_jean_reconocimiento_redes_neuronales(actividad1).ipynb - Colab.pdf
‚îÇ   ‚îú‚îÄ‚îÄ actividad 2
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Paez_Jean_EA_CNN_RNN.ipynb - Colab.pdf
‚îÇ   ‚îú‚îÄ‚îÄ actividad 3
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Paez_JeanCarlos_Evidencia3_RNN.ipynb - Colab.pdf
‚îÇ   ‚îú‚îÄ‚îÄ actividad 4
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ p√°ez_ram√≠rez_jean_carlos_ consideraciones √©ticas y legales.pdf
‚îÇ   ‚îÇ   
‚îú‚îÄ‚îÄ src
‚îÇ   ‚îî‚îÄ‚îÄ notebook
‚îÇ       ‚îú‚îÄ‚îÄ actividad 1
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ paez_jean_reconocimiento_redes_neuronales(actividad1).ipynb
‚îÇ       ‚îú‚îÄ‚îÄ actividad 2
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ Paez_Jean_EA_CNN_RNN.ipynb
‚îÇ       ‚îú‚îÄ‚îÄ actividad 3
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ Paez_JeanCarlos_Evidencia3_RNN.ipynb
‚îÇ       ‚îî‚îÄ‚îÄ actividad 4
‚îÇ           ‚îú‚îÄ‚îÄ Paez_Jean_EA4_Codigo.py
‚îÇ           ‚îî‚îÄ‚îÄ modelo_mejorado_lstm_fasttext.keras
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md
```

---

## ‚úÖ Actividad 1 ‚Äî Detecci√≥n de Fraudes Financieros con Red Neuronal

### Descripci√≥n

En esta actividad se desarrolla un modelo de red neuronal para detectar fraudes en transacciones con tarjetas de cr√©dito. Se identifican variables relevantes (features) como monto, ubicaci√≥n, hora, tipo de comercio, historial del cliente, entre otras, que alimentan el modelo.

El modelo es una red neuronal secuencial con una capa de entrada, dos capas ocultas con activaci√≥n ReLU y una capa de salida con activaci√≥n sigmoide, adecuada para clasificaci√≥n binaria (fraude/no fraude).

### Variables de Entrada (Features)

1. Monto de la transacci√≥n (`transaction_amount`)
2. Ubicaci√≥n del comercio vs. ubicaci√≥n habitual del cliente (`merchant_location_distance`)
3. Hora de la transacci√≥n (`transaction_hour`)
4. Tipo de comercio (`merchant_type`)
5. Historial del cliente (`customer_transaction_count`)
6. Frecuencia de transacciones recientes (`transactions_last_24h`)
7. Tipo de tarjeta (`card_type`)
8. Dispositivo usado (`device_id`)
9. Direcci√≥n IP (`ip_location_match`)
10. Pa√≠s de origen (`country_match`)

### Proceso de Entrenamiento

- Se genera un conjunto de datos sint√©tico con 10 caracter√≠sticas, con un desbalance de clases (95% leg√≠timos, 5% fraudes).
- Se divide en conjuntos de entrenamiento y prueba.
- Se normalizan los datos para mejorar el desempe√±o.
- Arquitectura del modelo:
  - Capa de entrada con 10 neuronas.
  - Dos capas ocultas con 16 y 8 neuronas respectivamente, activaci√≥n ReLU.
  - Capa de salida con 1 neurona y activaci√≥n sigmoide.
- Optimizaci√≥n con Adam y funci√≥n de p√©rdida `binary_crossentropy`.
- Entrenamiento durante 20 √©pocas con validaci√≥n interna.

### Resultados

- Precisi√≥n final de entrenamiento: ~98.66%
- Precisi√≥n final de validaci√≥n: ~99%
- La curva de precisi√≥n y p√©rdida muestra buen aprendizaje sin sobreajuste.
- Matriz de confusi√≥n:

|               | Predicho Leg√≠timo | Predicho Fraude |
|---------------|-------------------|-----------------|
| Real Leg√≠timo | 1897              | 3               |
| Real Fraude   | 33                | 67              |

- Reporte de clasificaci√≥n:

| Clase   | Precisi√≥n | Recall | F1-score | Soporte |
|---------|-----------|--------|----------|---------|
| Leg√≠timo| 0.98      | 1.00   | 0.99     | 1900    |
| Fraude  | 0.96      | 0.67   | 0.79     | 100     |
| **Accuracy global** |           |        | 0.98     | 2000    |

### Interpretaci√≥n

- El modelo identifica correctamente la mayor√≠a de transacciones leg√≠timas (recall 1.00).
- Tiene margen de mejora en la detecci√≥n de fraudes (recall 0.67), t√≠pico en problemas con clases desbalanceadas.
- La precisi√≥n para fraudes es alta (0.96), indicando que cuando predice fraude, suele acertar.
- El F1-score para fraudes (0.79) muestra un buen equilibrio, pero se recomienda mejorar la sensibilidad.

### Recomendaciones

1. Evaluar con un conjunto de prueba independiente para confirmar generalizaci√≥n.
2. Implementar *early stopping* para optimizar tiempo y recursos.
3. Guardar y documentar el modelo y sus hiperpar√°metros.
4. Monitorear desempe√±o en producci√≥n para detectar cambios en datos o entorno.
5. Explorar t√©cnicas de regularizaci√≥n (dropout, L1/L2) y aumento de datos si se ampl√≠a el dataset.
6. Analizar errores para mejorar calidad de datos o arquitectura.
7. Actualizar el modelo peri√≥dicamente para mantener precisi√≥n y relevancia.

### Visualizaci√≥n de Resultados

Se incluyen gr√°ficas de precisi√≥n y p√©rdida durante el entrenamiento y validaci√≥n, que muestran la evoluci√≥n positiva y estable del modelo.

---

## üìä Actividad 2 ‚Äî An√°lisis con CNN y RNN

### Parte 1: RNN para An√°lisis de Sentimiento

Se estudia un caso donde una empresa quiere clasificar comentarios de usuarios en positivos o negativos. Se propone usar una **RNN (LSTM o GRU)** como soluci√≥n. Incluye:

- Diagrama de arquitectura en Draw.io
- Identificaci√≥n de desaf√≠os t√©cnicos
- Soluciones aplicables con embeddings y redes bidireccionales

### Parte 2: CNN para Clasificaci√≥n MNIST

Se implementa una arquitectura **CNN** para el mismo problema de MNIST, obteniendo una mejora notable con respecto al modelo MLP.

- Capa convolucional + ReLU
- Capa de pooling
- Fully connected + Softmax
- Diagrama arquitect√≥nico hecho en Draw.io

### Resultados

- **Precisi√≥n en validaci√≥n:** 98.66%
- Gr√°ficas de precisi√≥n por √©poca
- Comparaci√≥n con resultados de la actividad 1 de ML

---

## üìù Actividad 3 ‚Äî Implementaci√≥n B√°sica de RNN para An√°lisis de Sentimiento

### Descripci√≥n

En esta actividad se implementa una red neuronal recurrente b√°sica (RNN) utilizando TensorFlow/Keras, enfocada en el an√°lisis de sentimiento de comentarios de productos. El objetivo es clasificar los comentarios en positivos o negativos, siguiendo los lineamientos de la evidencia de aprendizaje.

El modelo construido incluye:
- Una capa de embedding para la representaci√≥n vectorial de las palabras.
- Una capa SimpleRNN para el procesamiento secuencial de los datos.
- Una capa densa final con activaci√≥n sigmoide para la clasificaci√≥n binaria.

El conjunto de datos utilizado es reducido y simulado, lo que permite demostrar el funcionamiento general del modelo, aunque limita su capacidad de generalizaci√≥n.

### Proceso de Entrenamiento

- Preprocesamiento de los comentarios mediante tokenizaci√≥n y padding.
- Definici√≥n de la arquitectura secuencial con las capas mencionadas.
- Compilaci√≥n del modelo con optimizador Adam y funci√≥n de p√©rdida `binary_crossentropy`.
- Entrenamiento durante 10 √©pocas.
- Evaluaci√≥n del modelo con nuevos comentarios no vistos.

### Resultados

- Precisi√≥n de entrenamiento alcanz√≥ hasta 0.80 en la √∫ltima √©poca.
- La funci√≥n de p√©rdida disminuy√≥ progresivamente, indicando aprendizaje.
- Las predicciones para nuevos comentarios estuvieron cercanas a 0.5, reflejando la limitaci√≥n del modelo por el tama√±o del dataset y la presencia de frases nuevas.

### Conclusiones y Recomendaciones

- El modelo cumple con el objetivo acad√©mico de implementar y entender una RNN b√°sica para an√°lisis de sentimientos.
- Para mejorar el rendimiento, se recomienda:
  1. Ampliar el conjunto de datos con ejemplos reales y variados.
  2. Explorar arquitecturas m√°s avanzadas como LSTM o GRU.
  3. Realizar un preprocesamiento m√°s exhaustivo del texto (eliminaci√≥n de stopwords, normalizaci√≥n, embeddings preentrenados).
  4. Ajustar hiperpar√°metros y aumentar el n√∫mero de √©pocas si se dispone de m√°s datos.

---

## üß† Actividad 4 ‚Äî Mejora de Modelo LSTM con FastText y Optimizaci√≥n

### Descripci√≥n

En esta actividad se mejora un modelo de an√°lisis de sentimiento utilizando una red neuronal recurrente bidireccional (LSTM) con embeddings preentrenados FastText. Se optimizan hiperpar√°metros mediante Keras Tuner, se aplican t√©cnicas de regularizaci√≥n como dropout y batch normalization, y se exporta el modelo para producci√≥n.

Se incluyen an√°lisis detallados de resultados, visualizaciones, pruebas con frases personalizadas y consideraciones √©ticas sobre transparencia, equidad y privacidad.

### Implementaci√≥n

- Modelo bidireccional LSTM con embeddings FastText (300 dimensiones).
- Optimizaci√≥n de hiperpar√°metros: tasa de aprendizaje, tama√±o de lote, n√∫mero de √©pocas, dropout, unidades LSTM, etc.
- Regularizaci√≥n con dropout y batch normalization para evitar sobreajuste.
- Uso de Keras Tuner para b√∫squeda autom√°tica de hiperpar√°metros.
- Exportaci√≥n del modelo entrenado para uso en producci√≥n.
- Funciones para preprocesamiento, predicci√≥n personalizada y evaluaci√≥n.

### Resultados

- Precisi√≥n en validaci√≥n superior al 80%.
- Buen balance entre precisi√≥n y recall, con an√°lisis detallado de matriz de confusi√≥n.
- Visualizaciones de curvas de aprendizaje y matriz de confusi√≥n.
- Pruebas con frases personalizadas que muestran capacidad de clasificaci√≥n en textos reales.
- Identificaci√≥n de limitaciones y recomendaciones para mejorar.

### Consideraciones √âticas y Legales

- **Transparencia:** Documentaci√≥n clara del modelo, m√©tricas y decisiones.
- **Equidad:** Balanceo de clases y an√°lisis para evitar sesgos.
- **Privacidad:** Uso responsable de datos, anonimizaci√≥n y cumplimiento normativo.

### Recomendaciones

1. Aumento y diversificaci√≥n de datos para mejorar la generalizaci√≥n.
2. Ajuste fino de hiperpar√°metros y arquitectura para optimizar desempe√±o.
3. Implementaci√≥n de modelos ensemble para mayor robustez.
4. Manejo de neutralidad y ambig√ºedad en texto para clasificaciones m√°s precisas.
5. Evaluaci√≥n continua y monitoreo en producci√≥n para mantener efectividad.

---

## üõ†Ô∏è Requisitos

- Python 3.x
- TensorFlow / Keras
- Numpy, Matplotlib, Scikit-learn
- Keras Tuner
- FastText embeddings (archivo `cc.es.300.vec`)
- draw.io (para diagramas)

---

## ‚ñ∂Ô∏è Ejecuci√≥n

1. Clona este repositorio.
2. Accede a la carpeta correspondiente a la actividad que deseas ejecutar (`actividad1/`, `actividad2/`, `actividad3/`, `actividad4/`).
3. Abre y ejecuta los notebooks o scripts correspondientes.
4. Analiza los resultados y gr√°ficas generadas.

---

## üë§ Autor

Jean Carlos P√°ez Ram√≠rez