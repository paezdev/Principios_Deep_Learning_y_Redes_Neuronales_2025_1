# Reconocimiento con Redes Neuronales â€” Actividades 1 y 2

## DescripciÃ³n

Este repositorio corresponde al desarrollo progresivo de un proyecto de reconocimiento utilizando redes neuronales. Se documentan los experimentos y resultados de dos entregas principales:

- **Actividad 1:** DetecciÃ³n de fraudes financieros con un modelo bÃ¡sico de red neuronal.
- **Actividad 2:** AnÃ¡lisis de dos casos prÃ¡cticos aplicando redes **CNN** para imÃ¡genes y **RNN** para texto.

> **Nota:** El repositorio continuarÃ¡ ampliÃ¡ndose con nuevas carpetas y notebooks conforme avancen las siguientes actividades del curso.

---

## ðŸ“ Estructura del Proyecto

```
.
â”œâ”€â”€ docs
â”‚   â”œâ”€â”€ actividad 1
â”‚   â”‚   â””â”€â”€ paez_jean_reconocimiento_redes_neuronales(actividad1).ipynb - Colab.pdf
â”‚   â”œâ”€â”€ actividad 2
â”‚       â””â”€â”€ Paez_Jean_EA_CNN_RNN.ipynb - Colab.pdf
â”œâ”€â”€ src
â”‚   â””â”€â”€ notebook
â”‚       â”œâ”€â”€ actividad 1
â”‚       |   â””â”€â”€ paez_jean_reconocimiento_redes_neuronales(actividad1).ipynb
â”‚       â”œâ”€â”€ actividad 2
â”‚           â””â”€â”€ Paez_Jean_EA_CNN_RNN.ipynb
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

```

---

## âœ… Actividad 1 â€” DetecciÃ³n de Fraudes Financieros con Red Neuronal

### DescripciÃ³n

En esta actividad se desarrolla un modelo de red neuronal para detectar fraudes en transacciones con tarjetas de crÃ©dito. Se identifican variables relevantes (features) como monto, ubicaciÃ³n, hora, tipo de comercio, historial del cliente, entre otras, que alimentan el modelo.

El modelo es una red neuronal secuencial con una capa de entrada, dos capas ocultas con activaciÃ³n ReLU y una capa de salida con activaciÃ³n sigmoide, adecuada para clasificaciÃ³n binaria (fraude/no fraude).

### Variables de Entrada (Features)

1. Monto de la transacciÃ³n (`transaction_amount`)
2. UbicaciÃ³n del comercio vs. ubicaciÃ³n habitual del cliente (`merchant_location_distance`)
3. Hora de la transacciÃ³n (`transaction_hour`)
4. Tipo de comercio (`merchant_type`)
5. Historial del cliente (`customer_transaction_count`)
6. Frecuencia de transacciones recientes (`transactions_last_24h`)
7. Tipo de tarjeta (`card_type`)
8. Dispositivo usado (`device_id`)
9. DirecciÃ³n IP (`ip_location_match`)
10. PaÃ­s de origen (`country_match`)

### Proceso de Entrenamiento

- Se genera un conjunto de datos sintÃ©tico con 10 caracterÃ­sticas, con un desbalance de clases (95% legÃ­timos, 5% fraudes).
- Se divide en conjuntos de entrenamiento y prueba.
- Se normalizan los datos para mejorar el desempeÃ±o.
- Arquitectura del modelo:
  - Capa de entrada con 10 neuronas.
  - Dos capas ocultas con 16 y 8 neuronas respectivamente, activaciÃ³n ReLU.
  - Capa de salida con 1 neurona y activaciÃ³n sigmoide.
- OptimizaciÃ³n con Adam y funciÃ³n de pÃ©rdida `binary_crossentropy`.
- Entrenamiento durante 20 Ã©pocas con validaciÃ³n interna.

### Resultados

- PrecisiÃ³n final de entrenamiento: ~98.66%
- PrecisiÃ³n final de validaciÃ³n: ~99%
- La curva de precisiÃ³n y pÃ©rdida muestra buen aprendizaje sin sobreajuste.
- Matriz de confusiÃ³n:

|               | Predicho LegÃ­timo | Predicho Fraude |
|---------------|-------------------|-----------------|
| Real LegÃ­timo | 1897              | 3               |
| Real Fraude   | 33                | 67              |

- Reporte de clasificaciÃ³n:

| Clase   | PrecisiÃ³n | Recall | F1-score | Soporte |
|---------|-----------|--------|----------|---------|
| LegÃ­timo| 0.98      | 1.00   | 0.99     | 1900    |
| Fraude  | 0.96      | 0.67   | 0.79     | 100     |
| **Accuracy global** |           |        | 0.98     | 2000    |

### InterpretaciÃ³n

- El modelo identifica correctamente la mayorÃ­a de transacciones legÃ­timas (recall 1.00).
- Tiene margen de mejora en la detecciÃ³n de fraudes (recall 0.67), tÃ­pico en problemas con clases desbalanceadas.
- La precisiÃ³n para fraudes es alta (0.96), indicando que cuando predice fraude, suele acertar.
- El F1-score para fraudes (0.79) muestra un buen equilibrio, pero se recomienda mejorar la sensibilidad.

### Recomendaciones

1. Evaluar con un conjunto de prueba independiente para confirmar generalizaciÃ³n.
2. Implementar *early stopping* para optimizar tiempo y recursos.
3. Guardar y documentar el modelo y sus hiperparÃ¡metros.
4. Monitorear desempeÃ±o en producciÃ³n para detectar cambios en datos o entorno.
5. Explorar tÃ©cnicas de regularizaciÃ³n (dropout, L1/L2) y aumento de datos si se amplÃ­a el dataset.
6. Analizar errores para mejorar calidad de datos o arquitectura.
7. Actualizar el modelo periÃ³dicamente para mantener precisiÃ³n y relevancia.

### VisualizaciÃ³n de Resultados


Se incluyen grÃ¡ficas de precisiÃ³n y pÃ©rdida durante el entrenamiento y validaciÃ³n, que muestran la evoluciÃ³n positiva y estable del modelo.
---

## ðŸ“Š Actividad 2 â€” AnÃ¡lisis con CNN y RNN

### Parte 1: RNN para AnÃ¡lisis de Sentimiento

Se estudia un caso donde una empresa quiere clasificar comentarios de usuarios en positivos o negativos. Se propone usar una **RNN (LSTM o GRU)** como soluciÃ³n. Incluye:

- Diagrama de arquitectura en Draw.io
- IdentificaciÃ³n de desafÃ­os tÃ©cnicos
- Soluciones aplicables con embeddings y redes bidireccionales

### Parte 2: CNN para ClasificaciÃ³n MNIST

Se implementa una arquitectura **CNN** para el mismo problema de MNIST, obteniendo una mejora notable con respecto al modelo MLP.

- Capa convolucional + ReLU
- Capa de pooling
- Fully connected + Softmax
- Diagrama arquitectÃ³nico hecho en Draw.io

### Resultados

- **PrecisiÃ³n en validaciÃ³n:** 98.66%
- GrÃ¡ficas de precisiÃ³n por Ã©poca
- ComparaciÃ³n con resultados de la actividad 1 de ML

---

## ðŸ§  ConclusiÃ³n Final y Recomendaciones

CNN demostrÃ³ ser mÃ¡s adecuada para imÃ¡genes, mientras que las RNN se ajustan mejor a datos secuenciales como texto. La selecciÃ³n correcta de arquitectura impacta directamente en el rendimiento.

**Recomendaciones:**
- Usar regularizaciÃ³n y data augmentation en CNN
- Probar con datasets como CIFAR-10 o Fashion-MNIST
- Seguir documentando cada etapa en notebooks separados

---

## ðŸ› ï¸ Requisitos

- Python 3.x
- TensorFlow / Keras
- Numpy, Matplotlib, Scikit-learn
- draw.io (para visualizar diagramas)

---

## â–¶ï¸ EjecuciÃ³n

1. Clona este repositorio.
2. Accede a `actividad1/` o `actividad2/`.
3. Abre y ejecuta los notebooks correspondientes.
4. Analiza los resultados y grÃ¡ficas generadas.

---

## ðŸ‘¤ Autor

Jean Carlos PÃ¡ez RamÃ­rez

---

> *El proyecto se encuentra en desarrollo continuo como parte del curso de Deep Learning y Redes Neuronales.*