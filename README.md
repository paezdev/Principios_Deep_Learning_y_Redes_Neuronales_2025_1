# Principios de Deep Learning y Redes Neuronales â€” Actividades 1, 2, 3 y 4

## DescripciÃ³n

Este repositorio corresponde al desarrollo progresivo de un proyecto de reconocimiento utilizando redes neuronales. Se documentan los experimentos y resultados de cuatro entregas principales:

- **Actividad 1:** DetecciÃ³n de fraudes financieros con un modelo bÃ¡sico de red neuronal.
- **Actividad 2:** AnÃ¡lisis de dos casos prÃ¡cticos aplicando redes **CNN** para imÃ¡genes y **RNN** para texto.
- **Actividad 3:** ImplementaciÃ³n bÃ¡sica de una RNN para anÃ¡lisis de sentimiento de texto.
- **Actividad 4:** Mejora de un modelo LSTM bidireccional con embeddings FastText, optimizaciÃ³n de hiperparÃ¡metros con Keras Tuner, regularizaciÃ³n y exportaciÃ³n para producciÃ³n.

---

## ğŸ“ Estructura del Proyecto

```
.
â”œâ”€â”€ docs
â”‚   â”œâ”€â”€ actividad 1
â”‚   â”‚   â””â”€â”€ paez_jean_reconocimiento_redes_neuronales(actividad1).ipynb - Colab.pdf
â”‚   â”œâ”€â”€ actividad 2
â”‚   â”‚   â””â”€â”€ Paez_Jean_EA_CNN_RNN.ipynb - Colab.pdf
â”‚   â”œâ”€â”€ actividad 3
â”‚   â”‚   â””â”€â”€ Paez_JeanCarlos_Evidencia3_RNN.ipynb - Colab.pdf
â”‚   â”œâ”€â”€ actividad 4
â”‚   |         â”œâ”€â”€ best_model.keras
â”‚   |         â””â”€â”€ classification_report.txt
â”‚   |         â”œâ”€â”€ history.json
â”‚   |         â””â”€â”€ modelo_mejorado_lstm_fasttext.keras
â”‚   |         â””â”€â”€ pÃ¡ez_ramÃ­rez_jean_carlos_ implementaciÃ³n_final_red_neuronal.ipynb - Colab.pdf
â”‚   |         â””â”€â”€ tokenizer.pkl
â”‚   â”‚
|   |   
â”œâ”€â”€ src
â”‚   â””â”€â”€ notebook
â”‚       â”œâ”€â”€ actividad 1
â”‚       â”‚   â””â”€â”€ paez_jean_reconocimiento_redes_neuronales(actividad1).ipynb
â”‚       â”œâ”€â”€ actividad 2
â”‚       â”‚   â””â”€â”€ Paez_Jean_EA_CNN_RNN.ipynb
â”‚       â”œâ”€â”€ actividad 3
â”‚       â”‚   â””â”€â”€ Paez_JeanCarlos_Evidencia3_RNN.ipynb
â”‚       â””â”€â”€ actividad 4
â”‚           â””â”€â”€ pÃ¡ez_ramÃ­rez_jean_carlos__implementaciÃ³n_final_red_neuronal.ipynb
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## âœ… Actividad 1 â€” DetecciÃ³n de Fraudes Financieros con Red Neuronal

### DescripciÃ³n

En esta actividad se desarrolla un modelo de red neuronal para detectar fraudes en transacciones con tarjetas de crÃ©dito. Se identifican variables relevantes (features) como monto, ubicaciÃ³n, hora, tipo de comercio, historial del cliente, entre otras, que alimentan el modelo.

El modelo es una red neuronal secuencial con una capa de entrada, dos capas ocultas con activaciÃ³n ReLU y una capa de salida con activaciÃ³n sigmoide, adecuada para clasificaciÃ³n binaria (fraude/no fraude).

### Variables de Entrada (Features)

1. Monto de la transacciÃ³n (`transaction_amount`)
2. UbicaciÃ³n del comercio vs. ubicaciÃ³n habitual del cliente (`merchant_location_distance`)
3. Hora de la transacciÃ³n (`transaction_hour`)
4. Tipo de comercio (`merchant_type`)
5. Historial del cliente (`customer_transaction_count`)
6. Frecuencia de transacciones recientes (`transactions_last_24h`)
7. Tipo de tarjeta (`card_type`)
8. Dispositivo usado (`device_id`)
9. DirecciÃ³n IP (`ip_location_match`)
10. PaÃ­s de origen (`country_match`)

### Proceso de Entrenamiento

- Se genera un conjunto de datos sintÃ©tico con 10 caracterÃ­sticas, con un desbalance de clases (95% legÃ­timos, 5% fraudes).
- Se divide en conjuntos de entrenamiento y prueba.
- Se normalizan los datos para mejorar el desempeÃ±o.
- Arquitectura del modelo:
  - Capa de entrada con 10 neuronas.
  - Dos capas ocultas con 16 y 8 neuronas respectivamente, activaciÃ³n ReLU.
  - Capa de salida con 1 neurona y activaciÃ³n sigmoide.
- OptimizaciÃ³n con Adam y funciÃ³n de pÃ©rdida `binary_crossentropy`.
- Entrenamiento durante 20 Ã©pocas con validaciÃ³n interna.

### Resultados

- PrecisiÃ³n final de entrenamiento: ~98.66%
- PrecisiÃ³n final de validaciÃ³n: ~99%
- La curva de precisiÃ³n y pÃ©rdida muestra buen aprendizaje sin sobreajuste.
- Matriz de confusiÃ³n:

|               | Predicho LegÃ­timo | Predicho Fraude |
|---------------|-------------------|-----------------|
| Real LegÃ­timo | 1897              | 3               |
| Real Fraude   | 33                | 67              |

- Reporte de clasificaciÃ³n:

| Clase   | PrecisiÃ³n | Recall | F1-score | Soporte |
|---------|-----------|--------|----------|---------|
| LegÃ­timo| 0.98      | 1.00   | 0.99     | 1900    |
| Fraude  | 0.96      | 0.67   | 0.79     | 100     |
| **Accuracy global** |           |        | 0.98     | 2000    |

### InterpretaciÃ³n

- El modelo identifica correctamente la mayorÃ­a de transacciones legÃ­timas (recall 1.00).
- Tiene margen de mejora en la detecciÃ³n de fraudes (recall 0.67), tÃ­pico en problemas con clases desbalanceadas.
- La precisiÃ³n para fraudes es alta (0.96), indicando que cuando predice fraude, suele acertar.
- El F1-score para fraudes (0.79) muestra un buen equilibrio, pero se recomienda mejorar la sensibilidad.

### Recomendaciones

1. Evaluar con un conjunto de prueba independiente para confirmar generalizaciÃ³n.
2. Implementar *early stopping* para optimizar tiempo y recursos.
3. Guardar y documentar el modelo y sus hiperparÃ¡metros.
4. Monitorear desempeÃ±o en producciÃ³n para detectar cambios en datos o entorno.
5. Explorar tÃ©cnicas de regularizaciÃ³n (dropout, L1/L2) y aumento de datos si se amplÃ­a el dataset.
6. Analizar errores para mejorar calidad de datos o arquitectura.
7. Actualizar el modelo periÃ³dicamente para mantener precisiÃ³n y relevancia.

### VisualizaciÃ³n de Resultados

Se incluyen grÃ¡ficas de precisiÃ³n y pÃ©rdida durante el entrenamiento y validaciÃ³n, que muestran la evoluciÃ³n positiva y estable del modelo.

---

## ğŸ“Š Actividad 2 â€” AnÃ¡lisis con CNN y RNN

### Parte 1: RNN para AnÃ¡lisis de Sentimiento

Se estudia un caso donde una empresa quiere clasificar comentarios de usuarios en positivos o negativos. Se propone usar una **RNN (LSTM o GRU)** como soluciÃ³n. Incluye:

- Diagrama de arquitectura en Draw.io
- IdentificaciÃ³n de desafÃ­os tÃ©cnicos
- Soluciones aplicables con embeddings y redes bidireccionales

### Parte 2: CNN para ClasificaciÃ³n MNIST

Se implementa una arquitectura **CNN** para el mismo problema de MNIST, obteniendo una mejora notable con respecto al modelo MLP.

- Capa convolucional + ReLU
- Capa de pooling
- Fully connected + Softmax
- Diagrama arquitectÃ³nico hecho en Draw.io

### Resultados

- **PrecisiÃ³n en validaciÃ³n:** 98.66%
- GrÃ¡ficas de precisiÃ³n por Ã©poca
- ComparaciÃ³n con resultados de la actividad 1 de ML

---

## ğŸ“ Actividad 3 â€” ImplementaciÃ³n BÃ¡sica de RNN para AnÃ¡lisis de Sentimiento

### DescripciÃ³n

En esta actividad se implementa una red neuronal recurrente bÃ¡sica (RNN) utilizando TensorFlow/Keras, enfocada en el anÃ¡lisis de sentimiento de comentarios de productos. El objetivo es clasificar los comentarios en positivos o negativos, siguiendo los lineamientos de la evidencia de aprendizaje.

El modelo construido incluye:
- Una capa de embedding para la representaciÃ³n vectorial de las palabras.
- Una capa SimpleRNN para el procesamiento secuencial de los datos.
- Una capa densa final con activaciÃ³n sigmoide para la clasificaciÃ³n binaria.

El conjunto de datos utilizado es reducido y simulado, lo que permite demostrar el funcionamiento general del modelo, aunque limita su capacidad de generalizaciÃ³n.

### Proceso de Entrenamiento

- Preprocesamiento de los comentarios mediante tokenizaciÃ³n y padding.
- DefiniciÃ³n de la arquitectura secuencial con las capas mencionadas.
- CompilaciÃ³n del modelo con optimizador Adam y funciÃ³n de pÃ©rdida `binary_crossentropy`.
- Entrenamiento durante 10 Ã©pocas.
- EvaluaciÃ³n del modelo con nuevos comentarios no vistos.

### Resultados

- PrecisiÃ³n de entrenamiento alcanzÃ³ hasta 0.80 en la Ãºltima Ã©poca.
- La funciÃ³n de pÃ©rdida disminuyÃ³ progresivamente, indicando aprendizaje.
- Las predicciones para nuevos comentarios estuvieron cercanas a 0.5, reflejando la limitaciÃ³n del modelo por el tamaÃ±o del dataset y la presencia de frases nuevas.

### Conclusiones y Recomendaciones

- El modelo cumple con el objetivo acadÃ©mico de implementar y entender una RNN bÃ¡sica para anÃ¡lisis de sentimientos.
- Para mejorar el rendimiento, se recomienda:
  1. Ampliar el conjunto de datos con ejemplos reales y variados.
  2. Explorar arquitecturas mÃ¡s avanzadas como LSTM o GRU.
  3. Realizar un preprocesamiento mÃ¡s exhaustivo del texto (eliminaciÃ³n de stopwords, normalizaciÃ³n, embeddings preentrenados).
  4. Ajustar hiperparÃ¡metros y aumentar el nÃºmero de Ã©pocas si se dispone de mÃ¡s datos.

---

## ğŸ§  Actividad 4 â€” Mejora de Modelo LSTM con FastText y OptimizaciÃ³n

### DescripciÃ³n

En esta actividad se mejora un modelo de anÃ¡lisis de sentimiento utilizando una red neuronal recurrente bidireccional (LSTM) con embeddings preentrenados FastText. Se optimizan hiperparÃ¡metros mediante Keras Tuner, se aplican tÃ©cnicas de regularizaciÃ³n como dropout y batch normalization, y se exporta el modelo para producciÃ³n.

Se incluyen anÃ¡lisis detallados de resultados, visualizaciones, pruebas con frases personalizadas y consideraciones Ã©ticas sobre transparencia, equidad y privacidad.

### ImplementaciÃ³n

- Modelo bidireccional LSTM con embeddings FastText (300 dimensiones).
- OptimizaciÃ³n de hiperparÃ¡metros: tasa de aprendizaje, tamaÃ±o de lote, nÃºmero de Ã©pocas, dropout, unidades LSTM, etc.
- RegularizaciÃ³n con dropout y batch normalization para evitar sobreajuste.
- Uso de Keras Tuner para bÃºsqueda automÃ¡tica de hiperparÃ¡metros.
- ExportaciÃ³n del modelo entrenado para uso en producciÃ³n.
- Funciones para preprocesamiento, predicciÃ³n personalizada y evaluaciÃ³n.

### Resultados

- PrecisiÃ³n en validaciÃ³n superior al 80%.
- Buen balance entre precisiÃ³n y recall, con anÃ¡lisis detallado de matriz de confusiÃ³n.
- Visualizaciones de curvas de aprendizaje y matriz de confusiÃ³n.
- Pruebas con frases personalizadas que muestran capacidad de clasificaciÃ³n en textos reales.
- IdentificaciÃ³n de limitaciones y recomendaciones para mejorar.

### Consideraciones Ã‰ticas y Legales

- **Transparencia:** DocumentaciÃ³n clara del modelo, mÃ©tricas y decisiones.
- **Equidad:** Balanceo de clases y anÃ¡lisis para evitar sesgos.
- **Privacidad:** Uso responsable de datos, anonimizaciÃ³n y cumplimiento normativo.

### Recomendaciones

1. Aumento y diversificaciÃ³n de datos para mejorar la generalizaciÃ³n.
2. Ajuste fino de hiperparÃ¡metros y arquitectura para optimizar desempeÃ±o.
3. ImplementaciÃ³n de modelos ensemble para mayor robustez.
4. Manejo de neutralidad y ambigÃ¼edad en texto para clasificaciones mÃ¡s precisas.
5. EvaluaciÃ³n continua y monitoreo en producciÃ³n para mantener efectividad.

---

## ğŸ› ï¸ Requisitos

- Python 3.x
- TensorFlow / Keras
- Numpy, Matplotlib, Scikit-learn
- Keras Tuner
- FastText embeddings (archivo `cc.es.300.vec`)
- draw.io (para diagramas)

---

## â–¶ï¸ EjecuciÃ³n

1. Clona este repositorio.
2. Accede a la carpeta correspondiente a la actividad que deseas ejecutar (`actividad1/`, `actividad2/`, `actividad3/`, `actividad4/`).
3. Abre y ejecuta los notebooks o scripts correspondientes.
4. Analiza los resultados y grÃ¡ficas generadas.

---

## ğŸ‘¤ Autor

Jean Carlos PÃ¡ez RamÃ­rez