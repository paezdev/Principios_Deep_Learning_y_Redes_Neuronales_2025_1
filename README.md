# Reconocimiento con Redes Neuronales â€” Actividades 1 y 2

## DescripciÃ³n

Este repositorio corresponde al desarrollo progresivo de un proyecto de reconocimiento utilizando redes neuronales. Se documentan los experimentos y resultados de dos entregas principales:

- **Actividad 1:** Entrenamiento de un modelo bÃ¡sico (MLP) para clasificaciÃ³n de imÃ¡genes (MNIST).
- **Actividad 2:** AnÃ¡lisis de dos casos prÃ¡cticos aplicando redes **CNN** para imÃ¡genes y **RNN** para texto.

> **Nota:** El repositorio continuarÃ¡ ampliÃ¡ndose con nuevas carpetas y notebooks conforme avancen las siguientes actividades del curso.

---

## ðŸ“ Estructura del Proyecto

```
.
â”œâ”€â”€ docs
â”‚   â”œâ”€â”€ actividad 1
â”‚   â”‚   â””â”€â”€ paez_jean_reconocimiento_redes_neuronales(actividad1).ipynb - Colab.pdf
â”‚   â”œâ”€â”€ actividad 2
â”‚       â””â”€â”€ Paez_Jean_EA_CNN_RNN.ipynb - Colab.pdf
â”œâ”€â”€ src
â”‚   â””â”€â”€ notebook
â”‚       â”œâ”€â”€ actividad 1
â”‚       |   â””â”€â”€ paez_jean_reconocimiento_redes_neuronales(actividad1).ipynb
â”‚       â”œâ”€â”€ actividad 2
â”‚           â””â”€â”€ Paez_Jean_EA_CNN_RNN.ipynb
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

```

---

## âœ… Actividad 1 â€” Modelo MLP (MNIST)

### DescripciÃ³n

Se desarrolla y entrena un modelo bÃ¡sico de red neuronal multicapa (MLP) para clasificar imÃ¡genes del dataset MNIST. Se analiza el desempeÃ±o en funciÃ³n de precisiÃ³n y pÃ©rdida.

### Resultados Principales

- **PrecisiÃ³n final de entrenamiento:** ~98.66%
- **PrecisiÃ³n final de validaciÃ³n:** ~98.81%
- **PÃ©rdida final de entrenamiento:** ~0.05
- **PÃ©rdida final de validaciÃ³n:** ~0.05

El modelo generaliza correctamente, sin seÃ±ales de sobreajuste.

### Recomendaciones

- Evaluar con datos nuevos
- Aplicar *early stopping*
- Monitorear en producciÃ³n
- Implementar regularizaciÃ³n si se amplÃ­a el dataset

---

## ðŸ“Š Actividad 2 â€” AnÃ¡lisis con CNN y RNN

### Parte 1: RNN para AnÃ¡lisis de Sentimiento

Se estudia un caso donde una empresa quiere clasificar comentarios de usuarios en positivos o negativos. Se propone usar una **RNN (LSTM o GRU)** como soluciÃ³n. Incluye:

- Diagrama de arquitectura en Draw.io
- IdentificaciÃ³n de desafÃ­os tÃ©cnicos
- Soluciones aplicables con embeddings y redes bidireccionales

### Parte 2: CNN para ClasificaciÃ³n MNIST

Se implementa una arquitectura **CNN** para el mismo problema de MNIST, obteniendo una mejora notable con respecto al modelo MLP.

- Capa convolucional + ReLU
- Capa de pooling
- Fully connected + Softmax
- Diagrama arquitectÃ³nico hecho en Draw.io

### Resultados

- **PrecisiÃ³n en validaciÃ³n:** 98.66%
- GrÃ¡ficas de precisiÃ³n por Ã©poca
- ComparaciÃ³n con resultados de la actividad 1

---

## ðŸ§  ConclusiÃ³n Final y Recomendaciones

CNN demostrÃ³ ser mÃ¡s adecuada para imÃ¡genes, mientras que las RNN se ajustan mejor a datos secuenciales como texto. La selecciÃ³n correcta de arquitectura impacta directamente en el rendimiento.

**Recomendaciones:**
- Usar regularizaciÃ³n y data augmentation en CNN
- Probar con datasets como CIFAR-10 o Fashion-MNIST
- Seguir documentando cada etapa en notebooks separados

---

## ðŸ› ï¸ Requisitos

- Python 3.x
- TensorFlow / Keras
- Numpy, Matplotlib, Scikit-learn
- draw.io (para visualizar diagramas)

---

## â–¶ï¸ EjecuciÃ³n

1. Clona este repositorio.
2. Accede a `actividad1/` o `actividad2/`.
3. Abre y ejecuta los notebooks correspondientes.
4. Analiza los resultados y grÃ¡ficas generadas.

---

## ðŸ‘¤ Autor

Jean Carlos PÃ¡ez RamÃ­rez

---

> *El proyecto se encuentra en desarrollo continuo como parte del curso de Deep Learning y Redes Neuronales.*
```